{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcgWx8yM2gjN"
      },
      "source": [
        "# Exploring the Impact of Structured Representations in Scenario Generation Based on Large Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sIpzOSU2gjP"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7of_5Not2gjP",
        "outputId": "10f539aa-60dc-4fb5-f602-24e9bc9a7c00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lctgen-extended'...\n",
            "remote: Enumerating objects: 328, done.\u001b[K\n",
            "remote: Counting objects: 100% (328/328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (203/203), done.\u001b[K\n",
            "remote: Total 328 (delta 144), reused 275 (delta 99), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (328/328), 50.37 KiB | 2.96 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "base_dir = \"/content\"\n",
        "lctgen_extended_dir = f\"{base_dir}/lctgen-extended\"\n",
        "lctgen_dir = f\"{base_dir}/lctgen\"\n",
        "\n",
        "t = userdata.get(\"GITHUB_TOKEN\")\n",
        "u = \"WilliamLiao2015\"\n",
        "r = \"lctgen-extended\"\n",
        "\n",
        "\n",
        "os.chdir(base_dir)\n",
        "!git clone https://{t}@github.com/{u}/{r}.git\n",
        "os.chdir(lctgen_extended_dir)\n",
        "os.chdir(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uEzpXRhY2gjQ",
        "outputId": "c6992b03-ebd1-452c-ed2d-94e0fb6b211b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lctgen'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 146 (delta 25), reused 138 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 1.33 MiB | 5.71 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "\n",
        "# fetch codebase\n",
        "CODE_DIR = \"lctgen\"\n",
        "os.makedirs(f\"./{CODE_DIR}\", exist_ok=True)\n",
        "!git clone https://github.com/Ariostgx/lctgen.git $CODE_DIR\n",
        "os.chdir(lctgen_dir)\n",
        "sys.path.append(lctgen_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U3nMDyDk2gjQ",
        "outputId": "55384eef-903d-453b-e28d-1cfd10bd4133",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m826.4/826.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.6/419.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.9/288.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.3/516.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.0/670.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q -r requirements_colab.txt --quiet\n",
        "%pip install google-generativeai --quiet\n",
        "%pip install ipympl --quiet\n",
        "%pip install pymongo --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ecFSf4Go2gjQ",
        "outputId": "5742f937-1955-4896-a74c-9835db700912",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=17_TI-q4qkCOt988spWIZCqDLkZpMSptO\n",
            "From (redirected): https://drive.google.com/uc?id=17_TI-q4qkCOt988spWIZCqDLkZpMSptO&confirm=t&uuid=2925f8ad-8a42-4017-b49f-0a34818e923a\n",
            "To: /content/lctgen/data.zip\n",
            "100% 55.1M/55.1M [00:00<00:00, 62.9MB/s]\n",
            "Archive:  data.zip\n",
            " extracting: /content/lctgen/data/demo/waymo/2_5565.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/5_3594.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/5_3492.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/0_4693.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/4_5859.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/4_83.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/8_5321.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/8_330.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/0_5955.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/8_2315.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/9_4247.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/7_5300.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/3_1307.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/3_6019.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/3_702.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/6_5705.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/9_3335.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/9_267.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/8_1108.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/3_5690.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/2_467.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/9_3890.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/0_5769.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/7_5764.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/7_839.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/9_5302.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/2_3393.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/9_4795.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/9_3027.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/5_4416.pkl  \n",
            " extracting: /content/lctgen/data/demo/waymo/demo_map_vec.npy  \n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=17_TI-q4qkCOt988spWIZCqDLkZpMSptO -O data.zip\n",
        "!unzip data.zip -d {lctgen_dir}/data/demo/waymo/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6DBzdpU_2gjQ",
        "outputId": "287546ae-9a74-4e5a-84de-744fde8645b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1_s_35QO6OiHHgDxHHAa7Djadm-_I7Usr\n",
            "From (redirected): https://drive.google.com/uc?id=1_s_35QO6OiHHgDxHHAa7Djadm-_I7Usr&confirm=t&uuid=76c93f39-5b26-4a22-956a-98b76aeefe64\n",
            "To: /content/lctgen/example.ckpt\n",
            "100% 177M/177M [00:03<00:00, 51.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1_s_35QO6OiHHgDxHHAa7Djadm-_I7Usr -O example.ckpt\n",
        "!mkdir {lctgen_extended_dir}/checkpoints\n",
        "!mv example.ckpt {lctgen_extended_dir}/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CokR5Bww2gjR"
      },
      "outputs": [],
      "source": [
        "os.chdir(lctgen_extended_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hFQ7te2d2gjR"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tfoju1K2gjR"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nsOYEbAW2gjR"
      },
      "outputs": [],
      "source": [
        "from scripts.colab import setup_colab\n",
        "\n",
        "\n",
        "setup_colab()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agWN7vCG2gjR"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN5IQk082gjR"
      },
      "source": [
        "### OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3tRYr4W2gjR"
      },
      "outputs": [],
      "source": [
        "from llms.openai import get_openai_llm, inference_openai_llm\n",
        "\n",
        "\n",
        "llm_name = \"gpt-3.5-turbo\" # @param [\"gpt-3.5-turbo\", \"gpt-4\"]\n",
        "llm_model = get_openai_llm(llm_name)\n",
        "\n",
        "inference_llm = lambda query: inference_openai_llm(llm_model, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkseJgnu2gjR"
      },
      "source": [
        "### Google Generative AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA9c-48L2gjR"
      },
      "outputs": [],
      "source": [
        "from imports.system import pprint\n",
        "from imports.packages import genai\n",
        "\n",
        "\n",
        "for llm_name in genai.list_models():\n",
        "    pprint(llm_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0ZwLS682gjS"
      },
      "outputs": [],
      "source": [
        "from llms.google_generativeai import get_google_llm, inference_google_llm\n",
        "\n",
        "\n",
        "llm_name = \"gemini-1.0-pro-latest\" # @param [\"gemini-1.0-pro-latest\", \"gemini-1.5-pro-latest\"]\n",
        "llm_model = get_google_llm()\n",
        "\n",
        "inference_llm = lambda query: inference_google_llm(llm_model, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQWoTdSI2gjS"
      },
      "source": [
        "### Llama 3 Together.AI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciSvymcU2gjS"
      },
      "outputs": [],
      "source": [
        "from llms.llama3 import inference_llama3_llm\n",
        "\n",
        "\n",
        "llm_name = \"llama3\"\n",
        "\n",
        "inference_llm = inference_llama3_llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaDlyuxJ2gjS"
      },
      "source": [
        "### Llama 3 Local API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd8tjwdQ2gjS"
      },
      "outputs": [],
      "source": [
        "from llms.llama3_local import inference_llama3_llm\n",
        "\n",
        "\n",
        "llm_name = \"llama3 (local)\"\n",
        "\n",
        "inference_llm = inference_llama3_llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOAQMZZj2gjS"
      },
      "source": [
        "### LLM Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6SvO-TZ2gjS"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "from prompts.structured import scenarios, generate_prompt\n",
        "\n",
        "\n",
        "# query = 'V1 goes straight and collides with V2 while V2 turns left'  # @param {type:\"string\"}\n",
        "\n",
        "query = generate_prompt(random.choice(scenarios))\n",
        "\n",
        "print(\"Query:\")\n",
        "print(query)\n",
        "print()\n",
        "\n",
        "llm_result = inference_llm(query)\n",
        "\n",
        "print(\"LLM inference result:\")\n",
        "print(llm_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lVTsFUv2gjS"
      },
      "source": [
        "### Predefined LLM Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT-XEiAA2gjS"
      },
      "outputs": [],
      "source": [
        "query = \"Predefined result.\"\n",
        "llm_result = \"\"\"\n",
        "Actor Vector:\n",
        "- 'V1': [-1, 0, 0, 6, 4, 3, 3, 3]\n",
        "- 'V2': [0, 0, 1, 1, 1, 1, 1, 1]\n",
        "- 'V3': [2, 0, 0, 2, 4, 4, 3, 3]\n",
        "- 'V4': [1, 0, 1, 2, 4, 4, 3, 3]\n",
        "- 'V5': [0, 1, 2, 0, 0, 0, 0, 0]\n",
        "- 'V6': [0, 1, 2, 0, 0, 0, 0, 0]\n",
        "- 'V7': [0, 1, 2, 0, 0, 0, 0, 0]\n",
        "- 'V8': [0, 1, 2, 0, 0, 0, 0, 0]\n",
        "- 'V9': [0, 1, 1, 2, 4, 4, 4, 4]\n",
        "- 'V10': [0, 1, 1, 2, 4, 4, 4, 4]\n",
        "- 'V11': [0, 1, 1, 1, 4, 4, 4, 4]\n",
        "- 'V12': [3, 1, 0, 2, 4, 4, 4, 4]\n",
        "Map Vector:\n",
        "- 'Map': [2, 2, 2, 2, 1, 2]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qV85GSn2gjS"
      },
      "source": [
        "## Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVCIZ2jX2gjS"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O0IlukoM2gjT"
      },
      "outputs": [],
      "source": [
        "from imports.packages import np, plt, animation, HTML\n",
        "from scripts.visualize import visualize\n",
        "from utils.check_types import is_number\n",
        "\n",
        "from metrics.overlapped_area_rate import evaluate_overlapped_area_rate, visualize_overlapped_area_rate\n",
        "from metrics.road_collision_rate import evaluate_road_collision_rate, visualize_road_collision_rate\n",
        "from metrics.car_collision_rate import evaluate_car_collision_rate, visualize_car_collision_rate\n",
        "from metrics.minimum_speed_rate import evaluate_minimum_speed_rate, visualize_minimum_speed_rate\n",
        "\n",
        "\n",
        "visualizations = [\n",
        "    visualize_overlapped_area_rate,\n",
        "    visualize_road_collision_rate,\n",
        "    visualize_car_collision_rate,\n",
        "    visualize_minimum_speed_rate\n",
        "]\n",
        "evaluations = [\n",
        "    evaluate_overlapped_area_rate,\n",
        "    evaluate_road_collision_rate,\n",
        "    evaluate_car_collision_rate,\n",
        "    evaluate_minimum_speed_rate\n",
        "]\n",
        "\n",
        "\n",
        "def visualize_all(data, agents, t, visualizations=visualizations):\n",
        "    plt.gca().cla()\n",
        "    visualize(data, agents, t)\n",
        "    for i, method in enumerate(visualizations):\n",
        "        method(data, agents, t, 55 - 5 * (i + 1))\n",
        "\n",
        "def evaluate_all(data, agents, t, evaluations=evaluations):\n",
        "    results = {}\n",
        "\n",
        "    for evaluation in evaluations:\n",
        "        method_name = evaluation.__name__\n",
        "        print(f\"Evaluating method: {method_name}\")\n",
        "        results[evaluation] = []\n",
        "        for t in range(50):\n",
        "            results[evaluation].append(evaluation(data, agents, t))\n",
        "        print(evaluation.__doc__.format(result=np.mean(results[evaluation])))\n",
        "        print()\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def get_state_str(results, query=None, llm_result=None):\n",
        "    state_str = \"\"\n",
        "    lines = json.dumps({\n",
        "        \"query\": query if query else \"\",\n",
        "        \"llm_result\": llm_result,\n",
        "        \"results\": {evaluation.__name__: values for evaluation, values in results.items()}\n",
        "    }, indent=2).splitlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        previous = is_number(lines[i - 1].strip().replace(\",\", \"\")) if i > 0 else False\n",
        "        current = is_number(line.strip().replace(\",\", \"\"))\n",
        "        next = is_number(lines[i + 1].strip().replace(\",\", \"\")) if i < len(lines) - 1 else False\n",
        "        if current: state_str += line.strip()\n",
        "        elif next: state_str += line.rstrip()\n",
        "        elif previous: state_str += line.lstrip() + \"\\n\"\n",
        "        else: state_str += line + \"\\n\"\n",
        "\n",
        "    return state_str\n",
        "\n",
        "def get_anim_html(data, agents):\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(5, 5)\n",
        "    fig.set_dpi(100)\n",
        "\n",
        "    anim = animation.FuncAnimation(fig, lambda t: visualize_all(data, agents, t), frames=50, interval=100, repeat=False)\n",
        "    anim_html = anim.to_jshtml()\n",
        "\n",
        "    return anim_html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxp0Lhy42gjT"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ZKV-UYnC2gjT",
        "outputId": "659eccb9-e28c-4f2a-9e5f-46cbdb8a9522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inference_llm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-895bdc5ceadc>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenarios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mllm_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Note: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Query:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inference_llm' is not defined"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from imports.system import os, sys, json\n",
        "from configs.paths import lctgen_dir\n",
        "sys.path.append(lctgen_dir)\n",
        "\n",
        "from imports.packages import tqdm\n",
        "from configs.demo import cfg, model, map_vecs, map_ids\n",
        "from imports.trafficgen import *\n",
        "from scripts.colab import in_colab\n",
        "from scripts.inference import inference\n",
        "from prompts.structured import scenarios, generate_prompt\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from pymongo import MongoClient\n",
        "\n",
        "\n",
        "def get_database(uri: str, database_name: str) -> MongoClient:\n",
        "    client = MongoClient(uri)\n",
        "    return client[database_name]\n",
        "\n",
        "\n",
        "if not in_colab:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "\n",
        "cfg.merge_from_list([\"DATASET.DATA_LIST.ROOT\", f\"{lctgen_dir}/data/list\"])\n",
        "cfg.merge_from_list([\"DATASET.DATA_PATH\", f\"{lctgen_dir}/data/demo/waymo\"])\n",
        "\n",
        "n = 1\n",
        "\n",
        "user = \"williamliao2015\"\n",
        "password = os.getenv(\"MONGODB_PASSWORD\")\n",
        "\n",
        "database = get_database(f\"mongodb+srv://{user}:{password}@cluster-1.8eayemu.mongodb.net/?retryWrites=true&w=majority&appName=Cluster-1\", \"lctgen-extended\")\n",
        "\n",
        "\n",
        "for i in tqdm(range(n)):\n",
        "    clear_output()\n",
        "\n",
        "    query = generate_prompt(random.choice(scenarios))\n",
        "    llm_result = inference_llm(query).replace(\"Note: \", \"\")\n",
        "    print(\"Query:\")\n",
        "    print(query)\n",
        "    print()\n",
        "    print(\"LLM inference result:\")\n",
        "    print(llm_result)\n",
        "\n",
        "    data, agents = inference(model, cfg, map_vecs, map_ids, llm_result)\n",
        "    results = evaluate_all(data, agents, 0)\n",
        "\n",
        "    state_str = get_state_str(results, query=query, llm_result=llm_result)\n",
        "    anim_html = get_anim_html(data, agents)\n",
        "\n",
        "    database[\"batch-test\"].insert_one({\n",
        "        \"query\": query if query else \"\",\n",
        "        \"llm_name\": llm_name,\n",
        "        \"llm_result\": llm_result,\n",
        "        \"results\": {evaluation.__name__: values for evaluation, values in results.items()}\n",
        "    })\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZrk1Gtw2gjT"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRJBhpbb2gjT"
      },
      "outputs": [],
      "source": [
        "%matplotlib widget\n",
        "\n",
        "state_str = get_state_str(evaluate_all(data, agents, 0), query=query, llm_result=llm_result)\n",
        "\n",
        "anim_html = get_anim_html(data, agents)\n",
        "display(HTML(anim_html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iWu8gBc2gjT"
      },
      "source": [
        "### Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POW84qvC2gjT"
      },
      "outputs": [],
      "source": [
        "from configs.paths import base_dir\n",
        "from imports.system import datetime, os\n",
        "\n",
        "\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "save_to = f\"{base_dir}/lctgen_records\"\n",
        "\n",
        "if not os.path.exists(save_to):\n",
        "    os.mkdir(save_to)\n",
        "\n",
        "state_dir = f\"{save_to}/{current_time}.json\"\n",
        "print(f\"Saving state to \\\"{state_dir}\\\"\")\n",
        "with open(state_dir, \"w\", encoding=\"utf-8\") as fp:\n",
        "    fp.write(state_str)\n",
        "\n",
        "html_dir = f\"{save_to}/{current_time}.html\"\n",
        "print(f\"Saving HTML to \\\"{html_dir}\\\"\")\n",
        "with open(html_dir, \"w\", encoding=\"utf-8\") as fp:\n",
        "    fp.write(anim_html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O5LUW8l2gjT"
      },
      "outputs": [],
      "source": [
        "!zip -j {save_to}.zip {save_to}/*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "AGrDXkft7ztN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_oar(oar):\n",
        "    error = False\n",
        "    zeros = oar.count(0)\n",
        "    if zeros == len(oar):\n",
        "        error = True\n",
        "    return error\n",
        "def detect_rcr(rcr):\n",
        "    error = False\n",
        "    zeros = rcr.count(0)\n",
        "    if zeros != len(rcr):\n",
        "        error = True\n",
        "    return error\n",
        "def detect_ccr(ccr):\n",
        "    error = False\n",
        "    zeros = ccr.count(0)\n",
        "    if zeros == len(ccr):\n",
        "        error = True\n",
        "    return error\n",
        "def detect_msr(msr):\n",
        "    error = False\n",
        "    zeros = msr.count(0)\n",
        "    if zeros == len(msr):\n",
        "        error = True\n",
        "    return error"
      ],
      "metadata": {
        "id": "EO3AakyzGMR-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection = database[\"batch-test\"]\n",
        "\n",
        "error_data_dir = f\"{base_dir}/mongoDB_records\"\n",
        "oar_dir = error_data_dir + \"/overlapped_area_error\"\n",
        "rcr_dir = error_data_dir + \"/road_collision_error\"\n",
        "ccr_dir = error_data_dir + \"/car_collision_error\"\n",
        "msr_dir = error_data_dir + \"/minimum_speed_error\"\n",
        "\n",
        "for document in collection.find():\n",
        "    oar = document['results']['evaluate_overlapped_area_rate']\n",
        "    rcr = document['results']['evaluate_road_collision_rate']\n",
        "    ccr = document['results']['evaluate_car_collision_rate']\n",
        "    msr = document['results']['evaluate_minimum_speed_rate']\n",
        "    js = json.dumps({\n",
        "        \"id\": str(document['_id']),\n",
        "        \"query\": document['query']\n",
        "    },indent=4)\n",
        "    if detect_oar(oar):\n",
        "        file_name = f\"{oar_dir}/{str(document['_id'])}.json\"\n",
        "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "        with open(file_name, \"w\", encoding=\"utf-8\") as fp:\n",
        "            fp.write(js)\n",
        "    if detect_rcr(oar):\n",
        "        file_name = f\"{rcr_dir}/{str(document['_id'])}.json\"\n",
        "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "        with open(file_name, \"w\", encoding=\"utf-8\") as fp:\n",
        "            fp.write(js)\n",
        "    if detect_ccr(oar):\n",
        "        file_name = f\"{ccr_dir}/{str(document['_id'])}.json\"\n",
        "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "        with open(file_name, \"w\", encoding=\"utf-8\") as fp:\n",
        "            fp.write(js)\n",
        "    if detect_msr(oar):\n",
        "        file_name = f\"{msr_dir}/{str(document['_id'])}.json\"\n",
        "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "        with open(file_name, \"w\", encoding=\"utf-8\") as fp:\n",
        "            fp.write(js)"
      ],
      "metadata": {
        "id": "UxVjLSil72Mz"
      },
      "execution_count": 62,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}