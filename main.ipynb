{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Impact of Structured Representations in Scenario Generation Based on Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content')\n",
    "\n",
    "# fetch codebase\n",
    "CODE_DIR = 'lctgen'\n",
    "os.makedirs(f'./{CODE_DIR}', exist_ok=True)\n",
    "!git clone https://github.com/Ariostgx/lctgen.git $CODE_DIR\n",
    "os.chdir('/content/lctgen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements_colab.txt --quiet\n",
    "%pip install google-generativeai --quiet\n",
    "%pip install ipympl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=17_TI-q4qkCOt988spWIZCqDLkZpMSptO -O data.zip\n",
    "!unzip data.zip -d /content/lctgen/data/demo/waymo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1_s_35QO6OiHHgDxHHAa7Djadm-_I7Usr -O example.ckpt\n",
    "!mkdir /content/lctgen/checkpoints\n",
    "!mv example.ckpt /content/lctgen/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import ipywidgets\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "\n",
    "from google.colab import userdata\n",
    "from datetime import datetime\n",
    "from IPython.display import HTML, Javascript\n",
    "from matplotlib.patches import Wedge\n",
    "from pprint import pprint\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "\n",
    "# LCTGen\n",
    "from lctgen.config.default import get_config\n",
    "from lctgen.core.registry import registry\n",
    "from lctgen.datasets.waymo_open_motion import WaymoOpenMotionDataset\n",
    "from lctgen.inference.utils import output_formating_cot, map_retrival, get_map_data_batch, load_all_map_vectors\n",
    "from lctgen.models.utils import visualize_input_seq, visualize_output_seq, transform_traj_output_to_waymo_agent\n",
    "\n",
    "# TrafficGen\n",
    "from trafficgen.utils.typedef import *\n",
    "from trafficgen.utils.data_process.agent_process import WaymoAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_colab = \"google.colab\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = 'cfgs/demo_inference.yaml'\n",
    "cfg = get_config(cfg_file)\n",
    "\n",
    "model_cls = registry.get_model(cfg.MODEL.TYPE)\n",
    "model = model_cls.load_from_checkpoint(cfg.LOAD_CHECKPOINT_PATH, config=cfg, metrics=[], strict=False)\n",
    "model.eval()\n",
    "\n",
    "map_data_file = 'data/demo/waymo/demo_map_vec.npy'\n",
    "map_vecs, map_ids = load_all_map_vectors(map_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = userdata.get(\"OPENAI_ORGANIZATION\")\n",
    "openai.api_key = userdata.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = \"gpt-3.5-turbo\" # @param [\"gpt-3.5-turbo\", \"gpt-4\"]\n",
    "\n",
    "llm_cfg = get_config(\"/content/lctgen/lctgen/gpt/cfgs/attr_ind_motion/non_api_cot_attr_20m.yaml\")\n",
    "llm_cfg.merge_from_list([\"LLM.CODEX.MODEL\", llm_model_name])\n",
    "\n",
    "llm_model = registry.get_llm('codex')(llm_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'V1 speeds up and crashes V2 from back'  # @param {type:\"string\"}\n",
    "llm_result = llm_model.forward(query)\n",
    "\n",
    "print('LLM inference result:')\n",
    "print(llm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google AI Studio API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "for llm_model in genai.list_models():\n",
    "    pprint(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Set up the model\n",
    "generation_config = {\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": 1,\n",
    "    \"max_output_tokens\": 2048,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "]\n",
    "\n",
    "llm_model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\", generation_config=generation_config, safety_settings=safety_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'V1 goes straight and collides with V2 while V2 turns left'  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "prompt = \"## INSTRUCTIONS\\n\"\n",
    "\n",
    "with open(\"/content/lctgen/lctgen/gpt/prompts/attr_ind_motion/sys_non_api_cot_attr_20m.prompt\") as fp:\n",
    "    prompt += fp.read()\n",
    "\n",
    "prompt += \"\\n---\\n## QUERIES\\n\"\n",
    "\n",
    "with open(\"/content/lctgen/lctgen/gpt/prompts/attr_ind_motion/non_api_cot_attr_20m.prompt\") as fp:\n",
    "    prompt += fp.read()\n",
    "\n",
    "prompt = prompt.replace(\"INSERT_QUERY_HERE\", query)\n",
    "\n",
    "print(\"Prompt:\")\n",
    "print(prompt)\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "result = llm_model.generate_content(prompt)\n",
    "llm_result = result.text\n",
    "\n",
    "\n",
    "print(\"LLM inference result:\")\n",
    "print(llm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predefined Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = \"\"\"\n",
    "Actor Vector:\n",
    "- 'V1': [-1, 0, 0, 6, 4, 3, 3, 3]\n",
    "- 'V2': [0, 0, 1, 1, 1, 1, 1, 1]\n",
    "- 'V3': [2, 0, 0, 2, 4, 4, 3, 3]\n",
    "- 'V4': [1, 0, 1, 2, 4, 4, 3, 3]\n",
    "- 'V5': [0, 1, 2, 0, 0, 0, 0, 0]\n",
    "- 'V6': [0, 1, 2, 0, 0, 0, 0, 0]\n",
    "- 'V7': [0, 1, 2, 0, 0, 0, 0, 0]\n",
    "- 'V8': [0, 1, 2, 0, 0, 0, 0, 0]\n",
    "- 'V9': [0, 1, 1, 2, 4, 4, 4, 4]\n",
    "- 'V10': [0, 1, 1, 2, 4, 4, 4, 4]\n",
    "- 'V11': [0, 1, 1, 1, 4, 4, 4, 4]\n",
    "- 'V12': [3, 1, 0, 2, 4, 4, 4, 4]\n",
    "Map Vector:\n",
    "- 'Map': [2, 2, 2, 2, 1, 2]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
