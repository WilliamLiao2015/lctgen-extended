{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Impact of Structured Representations in Scenario Generation Based on Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "from configs.paths import base_dir, lctgen_extended_dir, lctgen_dir\n",
    "\n",
    "\n",
    "t = userdata.get(\"GITHUB_TOKEN\")\n",
    "u = \"WilliamLiao2015\"\n",
    "r = \"lctgen-extended\"\n",
    "\n",
    "\n",
    "os.chdir(base_dir)\n",
    "!git clone https://{t}@github.com/{u}/{r}.git\n",
    "os.chdir(lctgen_extended_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch codebase\n",
    "CODE_DIR = \"lctgen\"\n",
    "os.makedirs(f\"./{CODE_DIR}\", exist_ok=True)\n",
    "!git clone https://github.com/Ariostgx/lctgen.git $CODE_DIR\n",
    "os.chdir(lctgen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements_colab.txt --quiet\n",
    "%pip install google-generativeai --quiet\n",
    "%pip install ipympl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=17_TI-q4qkCOt988spWIZCqDLkZpMSptO -O data.zip\n",
    "!unzip data.zip -d {lctgen_dir}/data/demo/waymo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1_s_35QO6OiHHgDxHHAa7Djadm-_I7Usr -O example.ckpt\n",
    "!mkdir {lctgen_dir}/checkpoints\n",
    "!mv example.ckpt {lctgen_dir}/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(lctgen_extended_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from scripts.colab import setup_colab\n",
    "\n",
    "\n",
    "setup_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llms.openai import get_openai_llm, inference_openai_llm\n",
    "\n",
    "\n",
    "openai_llm_name = \"gpt-3.5-turbo\" # @param [\"gpt-3.5-turbo\", \"gpt-4\"]\n",
    "openai_llm_model = get_openai_llm(openai_llm_name)\n",
    "\n",
    "inference_llm = lambda query: inference_openai_llm(openai_llm_model, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Generative AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports.system import pprint\n",
    "from imports.packages import genai\n",
    "\n",
    "\n",
    "for google_llm_name in genai.list_models():\n",
    "    pprint(google_llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llms.google_generativeai import get_google_llm, inference_google_llm\n",
    "\n",
    "\n",
    "google_llm_name = \"gemini-1.0-pro-latest\" # @param [\"gemini-1.0-pro-latest\", \"gemini-1.5-pro-latest\"]\n",
    "google_llm_model = get_google_llm()\n",
    "\n",
    "inference_llm = lambda query: inference_google_llm(google_llm_model, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'V1 goes straight and collides with V2 while V2 turns left'  # @param {type:\"string\"}\n",
    "\n",
    "llm_result = inference_llm(query)\n",
    "\n",
    "print(\"LLM inference result:\")\n",
    "print(llm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predefined Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = \"\"\"\n",
    "Actor Vector:\n",
    "- 'V1': [-1, 0, 0, 6, 4, 3, 3, 3]\n",
    "- 'V2': [0, 0, 1, 1, 1, 1, 1, 1]\n",
    "- 'V3': [2, 0, 0, 2, 4, 4, 3, 3]\n",
    "- 'V4': [1, 0, 1, 2, 4, 4, 3, 3]\n",
    "- 'V5': [0, 1, 2, 0, 0, 0, 0, 0]\n",
    "- 'V6': [0, 1, 2, 0, 0, 0, 0, 0]\n",
    "- 'V7': [0, 1, 2, 0, 0, 0, 0, 0]\n",
    "- 'V8': [0, 1, 2, 0, 0, 0, 0, 0]\n",
    "- 'V9': [0, 1, 1, 2, 4, 4, 4, 4]\n",
    "- 'V10': [0, 1, 1, 2, 4, 4, 4, 4]\n",
    "- 'V11': [0, 1, 1, 1, 4, 4, 4, 4]\n",
    "- 'V12': [3, 1, 0, 2, 4, 4, 4, 4]\n",
    "Map Vector:\n",
    "- 'Map': [2, 2, 2, 2, 1, 2]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports.system import json\n",
    "from imports.packages import ipywidgets, Javascript\n",
    "\n",
    "\n",
    "def copy_text_button(text: str) -> ipywidgets.Widget:\n",
    "\tbutton = ipywidgets.Button(description=\"Copy\", icon=\"copy\")\n",
    "\toutput = ipywidgets.Output(layout=ipywidgets.Layout(display=\"none\"))\n",
    "\tcopy_js = Javascript(f\"navigator.clipboard.writeText({json.dumps(text)})\")\n",
    "\n",
    "\tdef on_click(_: ipywidgets.Button) -> None:\n",
    "\t\toutput.clear_output()\n",
    "\t\toutput.append_display_data(copy_js)\n",
    "\tbutton.on_click(on_click)\n",
    "\n",
    "\treturn ipywidgets.Box((button, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.inference import inference\n",
    "from configs.demo import cfg, model, map_vecs, map_ids\n",
    "\n",
    "\n",
    "data, agents = inference(model, cfg, map_vecs, map_ids, llm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports.packages import plt, animation, HTML\n",
    "from scripts.visualize import visualize\n",
    "from utils.check_types import is_number\n",
    "\n",
    "from metrics.overlapped_area_rate import evaluate_overlapped_area_rate, visualize_overlapped_area_rate\n",
    "from metrics.road_collision_rate import evaluate_road_collision_rate, visualize_road_collision_rate\n",
    "from metrics.car_collision_rate import evaluate_car_collision_rate, visualize_car_collision_rate\n",
    "from metrics.minimum_speed_rate import evaluate_minimum_speed_rate, visualize_minimum_speed_rate\n",
    "\n",
    "\n",
    "visualizations = [\n",
    "    visualize_overlapped_area_rate,\n",
    "    visualize_road_collision_rate,\n",
    "    visualize_car_collision_rate,\n",
    "    visualize_minimum_speed_rate\n",
    "]\n",
    "evaluations = [\n",
    "    evaluate_overlapped_area_rate,\n",
    "    evaluate_road_collision_rate,\n",
    "    evaluate_car_collision_rate,\n",
    "    evaluate_minimum_speed_rate\n",
    "]\n",
    "\n",
    "\n",
    "def visualize_all(data, agents, t, visualizations=visualizations):\n",
    "    plt.gca().cla()\n",
    "    visualize(data, agents, t)\n",
    "    for i, method in enumerate(visualizations):\n",
    "        method(data, agents, t, 55 - 5 * (i + 1))\n",
    "\n",
    "def evaluate_all(data, agents, t, evaluations=evaluations):\n",
    "    results = {}\n",
    "\n",
    "    for evaluation in evaluations:\n",
    "        method_name = evaluation.__name__\n",
    "        print(f\"Evaluating method: {method_name}\")\n",
    "        results[evaluation] = []\n",
    "        for t in range(50):\n",
    "            results[evaluation].append(evaluation(data, agents, t))\n",
    "        print(evaluation.__doc__.format(result=np.mean(results[evaluation])))\n",
    "        print()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_state_str(results, query=None, llm_result=None):\n",
    "    state_str = \"\"\n",
    "    lines = json.dumps({\n",
    "        \"query\": query if query else \"\",\n",
    "        \"llm_result\": llm_result,\n",
    "        \"results\": {evaluation.__name__: values for evaluation, values in results.items()}\n",
    "    }, indent=2).splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        previous = is_number(lines[i - 1].strip().replace(\",\", \"\")) if i > 0 else False\n",
    "        current = is_number(line.strip().replace(\",\", \"\"))\n",
    "        next = is_number(lines[i + 1].strip().replace(\",\", \"\")) if i < len(lines) - 1 else False\n",
    "        if current: state_str += line.strip()\n",
    "        elif next: state_str += line.rstrip()\n",
    "        elif previous: state_str += line.lstrip() + \"\\n\"\n",
    "        else: state_str += line + \"\\n\"\n",
    "\n",
    "    return state_str\n",
    "\n",
    "def get_anim_html(data, agents):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(5, 5)\n",
    "    fig.set_dpi(100)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, lambda t: visualize_all(data, agents, t), frames=50, interval=100, repeat=False)\n",
    "    anim_html = anim.to_jshtml()\n",
    "\n",
    "    return anim_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_str = get_state_str(evaluate_all(data, agents, 0), query=query, llm_result=llm_result)\n",
    "\n",
    "print(\"Copy state as text:\")\n",
    "display(copy_text_button(state_str))\n",
    "print()\n",
    "\n",
    "anim_html = get_anim_html(data, agents)\n",
    "display(HTML(anim_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports.system import datetime\n",
    "\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "save_to = f\"{base_dir}/lctgen_records\"\n",
    "\n",
    "if not os.path.exists(save_to):\n",
    "    os.mkdir(save_to)\n",
    "\n",
    "state_dir = f\"{save_to}/{current_time}.json\"\n",
    "print(f\"Saving state to \\\"{state_dir}\\\"\")\n",
    "with open(state_dir, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(state_str)\n",
    "\n",
    "html_dir = f\"{save_to}/{current_time}.html\"\n",
    "print(f\"Saving HTML to \\\"{html_dir}\\\"\")\n",
    "with open(html_dir, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(anim_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -j {save_to}.zip {save_to}/*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
